# 神经网络
## 6.1 神经网络的引入
### 6.1.1 感知器算法
感知器算法属于线性分类器：<br>
![2018-11-16.10.06.08-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.06.08-image.png)

感知器算法可图示如下：<br>
![2018-11-16.10.07.20-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.07.20-image.png)

### 6.1.2 利用感知器对OR进行分类
![2018-11-16.10.13.22-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.13.22-image.png)
### 6.1.3 神经网络的引入——XOR运算
XOR运算是一个典型的非线性分类问题。 

逻辑运算分类图：
![2018-11-16.10.11.40-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.11.40-image.png)

以两条直线来划分XOR，问题相当于分成了两步： 
1. 确定两条分界线，每个分界线实现对平面的一个分类；
2.  将第一步的结果组合 起来，实现正确分类。

![2018-11-16.10.16.39-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.16.39-image.png)
### 6.1.4 两层前馈神经网络
两层前馈神经网络：
- 第1层神经元完成第1步的工作，称为隐含层； 
- 第2层神经元称为输出层； 
- 最前面还有输入层。

![2018-11-16.10.20.08-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.20.08-image.png)

前面隐含层的功能是把输入的模式进行一个映射，映射到二维空间单位长度正方形的顶点。 

一般的两层感知器结构：
![2018-11-16.10.21.18-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.21.18-image.png)

### 6.1.5 三层感知器的分类能力
三层感知器能够解决任意区域组合的分类问题。
![2018-11-16.10.25.23-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.25.23-image.png)

### 6.1.6 神经网络的概念
神经网络是由大量简单的基本元件————神经元相互连接而成的自适应非线性动态系统。每个神经元的结构和功能比较简单，而大量神经元组合产生的系统行为却非常复杂。 

经典的McCulloch-Pitts模型：<br>
![2018-11-16.10.28.55-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.28.55-image.png)

## 6.2 神经网络基本概念
### 6.2.1 人工神经元及神经网络
人工神经元：生物神经元的简化模拟。
![2018-11-16.10.30.27-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.30.27-image.png)

<b>人工神经元间的互连</b>：信息传递路径轴突-突触-树突的简化； <br>
<b>连接的权值</b>：两个互连的神经元之间相互作用的强弱。

神经元的动作：<br>
![2018-11-16.10.32.49-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.32.49-image.png)

输出函数$$f$$：也称作用函数，非线性。
![2018-11-16.10.34.45-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.34.45-image.png)

### 6.2.2 BP神经网络模型
激活函数必须处处可导，一般都可使用S型函数

使用S型激活函数时BP网络输入与输出关系：
- 输入 $$net=x_{1}w_{1}+x_{2}w_{2}+\dots + x_{n}w_{n}$$
- 输出 $$y=f(net)=\frac{1}{1+e^{-net}}$$
- 输出的导数 $$f'(net)=\frac{1}{1+e^{-net}}-\frac{1}{({1+e^{-net})}^{2}}=y(1-y)$$

### 6.2.3 神经网络的学习
<b>学习</b>：神经网络的最重要特征之一。

<b>实质</b>：同一个训练集的样本输入输出模式反复作用于网络，网 络按照一定的训练规则自动调节神经元之间的连接强度或拓 扑结构，使实际输出满足期望的要求或者趋于稳定。 

<b>典型的权值修正方法</b>： Hebb学习规则、误差修正学习

#### 6.2.3.1 Hebb学习规则
如果神经网络中某一神经元与另一直接与其相连的神经 元同时处于兴奋状态，那么这两个神经元之间的连接强度应 该加强。

![2018-11-16.10.56.50-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.56.50-image.png)
#### 6.2.3.2 δ学习规则
![2018-11-16.10.57.50-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.10.57.50-image.png)

### 6.2.4 神经网络的结构分类
1. 分层结构：有明显层次，信息流向由输入层到输出层。 
2. 相互连接结构：没有明显层次，任意两个神经元之间可达，具有输出 单元到隐层单元或输入单元的反馈连接 。

## 6.3 前馈神经网络
### 6.3.1 感知器
![2018-11-16.11.04.48-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.11.04.48-image.png)
<br>
#### 6.3.1.1 结构特点：
- 只有两层（输入层、输出层）； 
- 两层单元之间为全互连； 
- 连接权值可调。
- 输出层神经元个数等于类别数（两类问题时输出层 为一个神经元）。

![2018-11-16.11.08.31-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.11.08.31-image.png)
![2018-11-16.11.09.06-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.11.09.06-image.png)

正确判决的关键：输出层每个神经元必须有一组合适的权值。 <br>
感知器采用监督学习算法得到权值； <br>
权值更新方法：δ学习规则。<br>

#### 6.3.1.2 算法描述
1. 设置初始权值$$w_{ij}(1)，w_{(n+1)j}(1)$$为第$$j$$个神经元的阈值
2. 输入新的模式向量
3. 计算神经元的实际输出

设第$$k$$次输入的模式向量为$$X_{k}$$，与第$$j$$个神经元相连的权向量为：$$W_{j}(k)=\left [ w_{1j}, w_{2j}, \dots ,w_{(n+1)j}\right ]^{T}$$

第$$j$$个神经元的实际输出为：$$y_{j}(k)=f[W_{j}^{T}(k)X_{k}], 1\leq j \leq M$$
4. 修正权值

![2018-11-16.11.18.14-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.11.18.14-image.png)
5. 转到第二步：当全部学习样本都能正确分类时，学习过程结束。

经验证明，当η随k的增加而减小时，算法一定收敛。

### 6.3.2 BP网络
BP网络：采用BP算法（Back-Propagation Training Algorithm） 的多层感知器

#### 6.3.2.1 多层感知器 
针对感知器学习算法的局限性：模式类必须线性可分。

![2018-11-16.11.26.29-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.11.26.29-image.png)

隐层单元的作用相当于特征检测器，提取输入模式中的有效信息，使输出单元处理的模式线性可分。

#### 6.3.2.2 BP算法
两个阶段：
1. 正向传播阶段：逐层状态更新
2. 反向传播阶段：误差

##### BP算法的学习过程
设：某层任一神经元$$j$$的输入为$$net_{j}$$，输出为$$y_{j}$$；相邻低一层中任一神经元$$i$$的输出为$$y_{i}$$。

$$net_{j}=\sum_{i}w_{ij}y_{i}$$<br>
$$y_{i}=f(net_{j})$$<br>
$$w_{ij}$$：神经元$$i$$与$$j$$之间的连接权。<br>
$$f(\cdot )$$：神经元的输出函数。

![2018-11-16.11.35.11-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.11.35.11-image.png)

![2018-11-16.11.36.10-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.11.36.10-image.png)

![2018-11-16.11.37.56-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.11.37.56-image.png)

##### BP算法步骤
![2018-11-16.11.38.41-image.png](https://raw.githubusercontent.com/luluhan123/ImageforMarkdown/master/2018-11-16.11.38.41-image.png)